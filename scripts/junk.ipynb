{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-19T00:42:48.176710Z",
     "iopub.status.busy": "2022-03-19T00:42:48.176428Z",
     "iopub.status.idle": "2022-03-19T00:42:49.115217Z",
     "shell.execute_reply": "2022-03-19T00:42:49.114322Z",
     "shell.execute_reply.started": "2022-03-19T00:42:48.176684Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-03-18 17:42:48,188]:[MainProcess][INFO]:[root] config_path: /home/gbiamby/proj/semafor/other_poj/twitter_comms/scripts/search_tweets.yaml\n",
      "[2022-03-18 17:42:48,188]:[MainProcess][INFO]:[root] csv_path: /home/gbiamby/proj/semafor/other_poj/twitter_comms/data/tweets/twitter_comms_dataset.csv\n",
      "[2022-03-18 17:42:48,984]:[MainProcess][INFO]:[root] Total tweet_ids: 110\n",
      "[2022-03-18 17:42:48,987]:[MainProcess][INFO]:[root] Saving tweets to /home/gbiamby/proj/semafor/other_poj/twitter_comms/data/tweets/twitter_comms_dataset.json\n",
      "[2022-03-18 17:42:48,987]:[MainProcess][INFO]:[root] Search args: {'bearer_token': 'AAAAAAAAAAAAAAAAAAAAAMUySgEAAAAAlWTFzd4DKy5Q9C%2B%2FhPhRRaIEM60%3D8LbvjJ5Wzn3wl8q8tgkQOLqajE9ATyVFvWUHSmcEnmCxRd7QrJ', 'endpoint': 'https://api.twitter.com/2/tweets/search/all', 'extra_headers_dict': None}\n",
      "[2022-03-18 17:42:48,988]:[MainProcess][INFO]:[root] ResultStream: ResultStream: \n",
      "\t{\n",
      "    \"endpoint\": \"https:\\/\\/api.twitter.com\\/2\\/tweets\\/search\\/all\",\n",
      "    \"request_parameters\": {\n",
      "        \"query\": \"id:1409530436481687559 OR id:1420581355176480770 OR id:1415615378546466819 OR id:1425871126014615558 OR id:1409480196944760833 OR id:1396357926990667784 OR id:1397088197054697473 OR id:1415037360706834438 OR id:1422531324997521408 OR id:1424781156554186757 OR id:1395738789868306434 OR id:1410109615732264966 OR id:1422331634947436544 OR id:1423432664900538368 OR id:1416065336219029513 OR id:1424275072412360714 OR id:1403333564377169926 OR id:1405118141890506762 OR id:1401474333084684296 OR id:1401003340012654597 OR id:1423800768960745473 OR id:1397317815733006339 OR id:1422227997613035528 OR id:1417673469064478720 OR id:1416131917095780356 OR id:1402823555528544259 OR id:1427457411162509312 OR id:1403038569644662792 OR id:1413018660562784256 OR id:1417865902905778182\",\n",
      "        \"end_time\": \"2021-08-16T00:00:00Z\",\n",
      "        \"max_results\": 100,\n",
      "        \"tweet.fields\": \"attachments,author_id,context_annotations,created_at,entities,geo,id,in_reply_to_user_id,lang,possibly_sensitive,public_metrics,referenced_tweets,source,text,withheld\",\n",
      "        \"user.fields\": \"description,location,public_metrics\",\n",
      "        \"media.fields\": \"media_key,type,duration_ms,height,preview_image_url,public_metrics,url,width,alt_text\",\n",
      "        \"place.fields\": \"full_name,id,country,country_code,geo,name,place_type\",\n",
      "        \"expansions\": \"attachments.media_keys,author_id,geo.place_id\"\n",
      "    },\n",
      "    \"max_tweets\": 135000\n",
      "}\n",
      "[2022-03-18 17:42:48,988]:[MainProcess][INFO]:[root] \n",
      "[2022-03-18 17:42:48,989]:[MainProcess][INFO]:[searchtweets.result_stream] using bearer token for authentication\n",
      "[2022-03-18 17:42:49,099]:[MainProcess][ERROR]:[searchtweets.result_stream]  HTTP Error code: 400: {\"errors\":[{\"parameters\":{\"query\":[\"id:1409530436481687559 OR id:1420581355176480770 OR id:1415615378546466819 OR id:1425871126014615558 OR id:1409480196944760833 OR id:1396357926990667784 OR id:1397088197054697473 OR id:1415037360706834438 OR id:1422531324997521408 OR id:1424781156554186757 OR id:1395738789868306434 OR id:1410109615732264966 OR id:1422331634947436544 OR id:1423432664900538368 OR id:1416065336219029513 OR id:1424275072412360714 OR id:1403333564377169926 OR id:1405118141890506762 OR id:1401474333084684296 OR id:1401003340012654597 OR id:1423800768960745473 OR id:1397317815733006339 OR id:1422227997613035528 OR id:1417673469064478720 OR id:1416131917095780356 OR id:1402823555528544259 OR id:1427457411162509312 OR id:1403038569644662792 OR id:1413018660562784256 OR id:1417865902905778182\"]},\"message\":\"There were errors processing your request: Reference to invalid operator 'id'. Operator is not available in current product or product packaging. Please refer to complete available operator list at http://t.co/operators. (at position 157), Reference to invalid field 'id' (at position 547), Reference to invalid field 'id' (at position 729), Reference to invalid operator 'id'. Operator is not available in current product or product packaging. Please refer to complete available operator list at http://t.co/operators. (at position 573), Reference to invalid field 'id' (at position 313), Reference to invalid field 'id' (at position 599), Reference to invalid operator 'id'. Operator is not available in current product or product packaging. Please refer to complete available operator list at http://t.co/operators. (at position 521), Reference to invalid operator 'id'. Operator is not available in current product or product packaging. Please refer to complete available operator list at http://t.co/operators. (at position 755), Reference to invalid operator 'id'. Operator is not available in current product or product packaging. Please refer to complete available operator list at http://t.co/operators. (at position 105), Reference to invalid operator 'id'. Operator is not available in current product or product packaging. Please refer to complete available operator list at http://t.co/operators. (at position 339), Reference to invalid field 'id' (at position 365), Reference to invalid operator 'id'. Operator is not available in current product or product packaging. Please refer to complete available operator list at http://t.co/operators. (at position 703), Reference to invalid field 'id' (at position 131), Reference to invalid field 'id' (at position 183), Reference to invalid field 'id' (at position 1), Reference to invalid field 'id' (at position 625), Reference to invalid operator 'id'. Operator is not available in current product or product packaging. Please refer to complete available operator list at http://t.co/operators. (at position 651), Reference to invalid field 'id' (at position 209), Reference to invalid operator 'id'. Operator is not available in current product or product packaging. Please refer to complete available operator list at http://t.co/operators. (at position 287), Reference to invalid field 'id' (at position 27), Reference to invalid operator 'id'. Operator is not available in current product or product packaging. Please refer to complete available operator list at http://t.co/operators. (at position 469), Reference to invalid operator 'id'. Operator is not available in current product or product packaging. Please refer to complete available operator list at http://t.co/operators. (at position 235), Reference to invalid field 'id' (at position 495), Reference to invalid field 'id' (at position 677), Reference to invalid operator 'id'. Operator is not available in current product or product packaging. Please refer to complete available operator list at http://t.co/operators. (at position 417), Reference to invalid field 'id' (at position 443), Reference to invalid field 'id' (at position 261), Reference to invalid operator 'id'. Operator is not available in current product or product packaging. Please refer to complete available operator list at http://t.co/operators. (at position 53), Reference to invalid field 'id' (at position 79), Reference to invalid operator 'id'. Operator is not available in current product or product packaging. Please refer to complete available operator list at http://t.co/operators. (at position 391), Reference to invalid field 'id' (at position 703), Reference to invalid field 'id' (at position 339), Reference to invalid operator 'id'. Operator is not available in current product or product packaging. Please refer to complete available operator list at http://t.co/operators. (at position 183), Reference to invalid operator 'id'. Operator is not available in current product or product packaging. Please refer to complete available operator list at http://t.co/operators. (at position 365), Reference to invalid operator 'id'. Operator is not available in current product or product packaging. Please refer to complete available operator list at http://t.co/operators. (at position 131), Reference to invalid field 'id' (at position 105), Reference to invalid field 'id' (at position 521), Reference to invalid operator 'id'. Operator is not available in current product or product packaging. Please refer to complete available operator list at http://t.co/operators. (at position 313), Reference to invalid operator 'id'. Operator is not available in current product or product packaging. Please refer to complete available operator list at http://t.co/operators. (at position 599), Reference to invalid field 'id' (at position 755), Reference to invalid operator 'id'. Operator is not available in current product or product packaging. Please refer to complete available operator list at http://t.co/operators. (at position 1), Reference to invalid field 'id' (at position 157), Reference to invalid field 'id' (at position 573), Reference to invalid operator 'id'. Operator is not available in current product or product packaging. Please refer to complete available operator list at http://t.co/operators. (at position 547), Reference to invalid operator 'id'. Operator is not available in current product or product packaging. Please refer to complete available operator list at http://t.co/operators. (at position 729), Reference to invalid field 'id' (at position 391), Reference to invalid operator 'id'. Operator is not available in current product or product packaging. Please refer to complete available operator list at http://t.co/operators. (at position 261), Reference to invalid operator 'id'. Operator is not available in current product or product packaging. Please refer to complete available operator list at http://t.co/operators. (at position 443), Reference to invalid field 'id' (at position 417), Reference to invalid operator 'id'. Operator is not available in current product or product packaging. Please refer to complete available operator list at http://t.co/operators. (at position 495), Reference to invalid operator 'id'. Operator is not available in current product or product packaging. Please refer to complete available operator list at http://t.co/operators. (at position 677), Reference to invalid field 'id' (at position 235), Reference to invalid field 'id' (at position 651), Reference to invalid field 'id' (at position 469), Reference to invalid field 'id' (at position 287), Reference to invalid operator 'id'. Operator is not available in current product or product packaging. Please refer to complete available operator list at http://t.co/operators. (at position 209), Reference to invalid operator 'id'. Operator is not available in current product or product packaging. Please refer to complete available operator list at http://t.co/operators. (at position 625), Reference to invalid field 'id' (at position 53), Reference to invalid operator 'id'. Operator is not available in current product or product packaging. Please refer to complete available operator list at http://t.co/operators. (at position 79), Reference to invalid operator 'id'. Operator is not available in current product or product packaging. Please refer to complete available operator list at http://t.co/operators. (at position 27)\"}],\"title\":\"Invalid Request\",\"detail\":\"One or more parameters to your request was invalid.\",\"type\":\"https://api.twitter.com/2/problems/invalid-request\"} | Bad Request\n",
      "[2022-03-18 17:42:49,100]:[MainProcess][ERROR]:[searchtweets.result_stream]  Request payload: {'query': 'id:1409530436481687559 OR id:1420581355176480770 OR id:1415615378546466819 OR id:1425871126014615558 OR id:1409480196944760833 OR id:1396357926990667784 OR id:1397088197054697473 OR id:1415037360706834438 OR id:1422531324997521408 OR id:1424781156554186757 OR id:1395738789868306434 OR id:1410109615732264966 OR id:1422331634947436544 OR id:1423432664900538368 OR id:1416065336219029513 OR id:1424275072412360714 OR id:1403333564377169926 OR id:1405118141890506762 OR id:1401474333084684296 OR id:1401003340012654597 OR id:1423800768960745473 OR id:1397317815733006339 OR id:1422227997613035528 OR id:1417673469064478720 OR id:1416131917095780356 OR id:1402823555528544259 OR id:1427457411162509312 OR id:1403038569644662792 OR id:1413018660562784256 OR id:1417865902905778182', 'end_time': '2021-08-16T00:00:00Z', 'max_results': 100, 'tweet.fields': 'attachments,author_id,context_annotations,created_at,entities,geo,id,in_reply_to_user_id,lang,possibly_sensitive,public_metrics,referenced_tweets,source,text,withheld', 'user.fields': 'description,location,public_metrics', 'media.fields': 'media_key,type,duration_ms,height,preview_image_url,public_metrics,url,width,alt_text', 'place.fields': 'full_name,id,country,country_code,geo,name,place_type', 'expansions': 'attachments.media_keys,author_id,geo.place_id'}\n",
      "[2022-03-18 17:42:49,100]:[MainProcess][ERROR]:[searchtweets.result_stream] Quitting... \n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-02f82d2db4e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    135\u001b[0m     )\n\u001b[1;32m    136\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-41-02f82d2db4e7>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0mtweet_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtweet_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m110\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Total tweet_ids: {len(tweet_ids)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m     \u001b[0mrehydrate_tweets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtweet_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-41-02f82d2db4e7>\u001b[0m in \u001b[0;36mrehydrate_tweets\u001b[0;34m(args, tweet_ids)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"ResultStream: {str(rs)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mpage_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m             \u001b[0msave_page\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAFTER_API_CALL_SLEEP_SECONDS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/proj/semafor/datasets/twitter/tools/search-tweets-python/searchtweets/result_stream.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;31m#self.check_counts() #TODO: not needed if no Tweet Parser being used.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream_started\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/proj/semafor/datasets/twitter/tools/search-tweets-python/searchtweets/result_stream.py\u001b[0m in \u001b[0;36mexecute_request\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    413\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m         resp = request(session=self.session,\n\u001b[0m\u001b[1;32m    416\u001b[0m                        \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m                        request_parameters=self.request_parameters)\n",
      "\u001b[0;32m~/proj/semafor/datasets/twitter/tools/search-tweets-python/searchtweets/result_stream.py\u001b[0m in \u001b[0;36mretried_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m                     \u001b[0;31m#Other errors are a \"one and done\", no use in retrying error...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Quitting... '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "https://developer.twitter.com/en/docs/twitter-api/tweets/search/integrate/build-a-query\n",
    "\"\"\"\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "from argparse import ArgumentParser, Namespace\n",
    "from pathlib import Path\n",
    "from time import sleep\n",
    "from typing import Any, Dict, List, cast\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from searchtweets import ResultStream, gen_request_parameters, load_credentials\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logging.basicConfig(\n",
    "    level=os.environ.get(\"LOGLEVEL\", \"INFO\"),\n",
    "    format=\"[%(asctime)s]:[%(processName)-11s]\" + \"[%(levelname)-s]:[%(name)s] %(message)s\",\n",
    ")\n",
    "\n",
    "\n",
    "# PAGE_SIZE, value between 10 and 100, is passed into the \"max_results\" parameter of pagination\n",
    "# (https://developer.twitter.com/en/docs/twitter-api/pagination)\n",
    "PAGE_SIZE = 100\n",
    "# MAX_TWEETS is a parameter specific to the search_tweets python library. It caps how many tweets\n",
    "# for the entire session, i.e,, across multiple pages:\n",
    "MAX_TWEETS = 135000\n",
    "# Time to wait between each API request:\n",
    "AFTER_API_CALL_SLEEP_SECONDS = 1\n",
    "\n",
    "\n",
    "def batchify(iterable, batch_size=1):\n",
    "    \"\"\"Splits an iterable / list-like into batches of size n\"\"\"\n",
    "    l = len(iterable)\n",
    "    for ndx in range(0, l, batch_size):\n",
    "        yield iterable[ndx : min(ndx + batch_size, l)]\n",
    "\n",
    "\n",
    "def rehydrate_tweets(args: Namespace, tweet_ids: List[str]) -> None:\n",
    "    \"\"\"\n",
    "    Rehydrate tweets from tweet_ids to json with data about each tweet, including\n",
    "    embedded images, videos, etc.\n",
    "    \"\"\"\n",
    "    config_path = Path(\"./search_tweets.yaml\").resolve()\n",
    "    filename = (args.output_dir / f\"{args.name}.json\").resolve()\n",
    "    assert config_path.exists(), str(config_path)\n",
    "    assert not filename.exists(), str(filename)\n",
    "    search_args = load_credentials(filename=config_path)\n",
    "    # load_credentials() fails to load the \"endpoint\" from the search_tweets.yaml file,\n",
    "    # so set it manually here:\n",
    "    search_args[\"endpoint\"] = \"https://api.twitter.com/2/tweets/search/all\"\n",
    "    logger.info(f\"Saving tweets to {filename}\")\n",
    "    logger.info(f\"Search args: {search_args}\")\n",
    "\n",
    "    # See here for restrictions on length of each API call. 1024 characters for\n",
    "    # academic license, 512 characters otherwise:\n",
    "    # https://developer.twitter.com/en/docs/twitter-api/tweets/search/integrate/build-a-query#limits.\n",
    "    # So adjust the tweets_per_batch so as not to exceed these limits:\n",
    "    tweets_per_batch = 30\n",
    "    for batch in batchify(tweet_ids, tweets_per_batch):\n",
    "        # Build API Query\n",
    "        query_str = get_search_phrase(batch)\n",
    "        search_query = gen_request_parameters(\n",
    "            query_str,\n",
    "            results_per_call=PAGE_SIZE,\n",
    "            media_fields=\"media_key,type,duration_ms,height,preview_image_url,public_metrics,url,width,alt_text\",\n",
    "            place_fields=\"full_name,id,country,country_code,geo,name,place_type\",\n",
    "            tweet_fields=\"attachments,author_id,context_annotations,created_at,entities,geo,id,in_reply_to_user_id,lang,possibly_sensitive,public_metrics,referenced_tweets,source,text,withheld\",\n",
    "            user_fields=\"description,location,public_metrics\",\n",
    "            expansions=\"attachments.media_keys,author_id,geo.place_id\",\n",
    "            end_time=\"2021-08-16 00:00\",\n",
    "        )\n",
    "        # logger.info(f\"Search query: {search_query}\")\n",
    "\n",
    "        # Get Tweets\n",
    "        rs = ResultStream(\n",
    "            request_parameters=search_query,\n",
    "            max_tweets=MAX_TWEETS,\n",
    "            max_pages=2,\n",
    "            output_format=\"a\",\n",
    "            **search_args,\n",
    "        )\n",
    "        logger.info(f\"ResultStream: {str(rs)}\")\n",
    "        logger.info(\"\")\n",
    "        for page_num, page in enumerate(rs.stream()):\n",
    "            save_page(page, args, filename)\n",
    "        sleep(AFTER_API_CALL_SLEEP_SECONDS)\n",
    "\n",
    "\n",
    "def save_page(page, args, filename: Path):\n",
    "    with open(filename, \"a\") as f:\n",
    "        # logger.info(f\"keys: {page.keys()}\")\n",
    "        # for tweet in page[\"data\"]:\n",
    "        #     f.write(json.dumps(tweet, sort_keys=True) + \"\\n\")\n",
    "        f.write(json.dumps(page, sort_keys=True) + \"\\n\")\n",
    "\n",
    "\n",
    "def get_search_phrase(tweet_id_batch):\n",
    "    return \" OR \".join(list(map(lambda _id: f\"id:{_id}\", tweet_id_batch)))\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    # Prepare paths:\n",
    "    config_path = Path(\"./search_tweets.yaml\").resolve()\n",
    "    csv_path = args.csv_path.resolve()\n",
    "    logger.info(f\"config_path: {config_path}\")\n",
    "    logger.info(f\"csv_path: {csv_path}\")\n",
    "    assert config_path.exists, str(config_path)\n",
    "    assert csv_path.exists(), str(csv_path)\n",
    "    df = pd.read_csv(csv_path, dtype={\"tweet_id\": int})\n",
    "    tweet_ids = df.tweet_id.astype(str).values.tolist()[:110]\n",
    "    logger.info(f\"Total tweet_ids: {len(tweet_ids)}\")\n",
    "    rehydrate_tweets(args, tweet_ids)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"--output_dir\",\n",
    "        type=Path,\n",
    "        default=Path(\"../data/tweets\").resolve(),\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--name\",\n",
    "        type=str,\n",
    "        default=\"twitter_comms_dataset\",\n",
    "        help=\"Used as part of output file name.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--csv_path\",\n",
    "        type=Path,\n",
    "        default=\"../data/tweets/twitter_comms_dataset.csv\",\n",
    "        help=\"Path to .csv file containing tweet_id's to rehydrate.\",\n",
    "    )\n",
    "    args = parser.parse_args(args=[])\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sem-unfoil2",
   "language": "python",
   "name": "sem-unfoil2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
